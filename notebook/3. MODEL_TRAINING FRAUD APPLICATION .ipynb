{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92e48866",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25791a74",
   "metadata": {},
   "source": [
    "#### 1.1 Import Data and Required Packages\n",
    "##### Importing Pandas, Numpy, Matplotlib, Seaborn and Warings Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b080dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "# Modelling\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45079ad",
   "metadata": {},
   "source": [
    "#### Import the CSV Data as Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11c6255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20634923",
   "metadata": {},
   "source": [
    "#### Show Top 5 Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e412a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdeed20",
   "metadata": {},
   "source": [
    "#### 2. SCALING 'TIME' AND 'AMOUNT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a5a278",
   "metadata": {},
   "source": [
    "#### Preparing X and Y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "978a0861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V20       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...  0.251412 -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ... -0.069083 -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...  0.524980  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ... -0.208038 -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...  0.408542 -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['Class'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e4b7bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "284802    0\n",
       "284803    0\n",
       "284804    0\n",
       "284805    0\n",
       "284806    0\n",
       "Name: Class, Length: 284807, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Class']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a126480e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227845, 30), (56962, 30))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1011f46e",
   "metadata": {},
   "source": [
    "#### Prepping for data scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "791f8088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numerical_features = ['Time', 'Amount']\n",
    "\n",
    "# Create transformation pipeline for numerical value in case if we need to process numerical value through \n",
    "# multiple steps\n",
    "num_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        # Add to the pipeline if need to handle missing value\n",
    "        #(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"robust scaler\", RobustScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"RobustScaler\", num_pipeline, numerical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "013fe22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>scaled_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43428</th>\n",
       "      <td>-16.526507</td>\n",
       "      <td>8.584972</td>\n",
       "      <td>-18.649853</td>\n",
       "      <td>9.505594</td>\n",
       "      <td>-13.793819</td>\n",
       "      <td>-2.832404</td>\n",
       "      <td>-16.701694</td>\n",
       "      <td>7.517344</td>\n",
       "      <td>-8.507059</td>\n",
       "      <td>-14.110184</td>\n",
       "      <td>...</td>\n",
       "      <td>1.190739</td>\n",
       "      <td>-1.127670</td>\n",
       "      <td>-2.358579</td>\n",
       "      <td>0.673461</td>\n",
       "      <td>-1.413700</td>\n",
       "      <td>-0.462762</td>\n",
       "      <td>-2.018575</td>\n",
       "      <td>-1.042804</td>\n",
       "      <td>-0.507399</td>\n",
       "      <td>4.785874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49906</th>\n",
       "      <td>0.339812</td>\n",
       "      <td>-2.743745</td>\n",
       "      <td>-0.134070</td>\n",
       "      <td>-1.385729</td>\n",
       "      <td>-1.451413</td>\n",
       "      <td>1.015887</td>\n",
       "      <td>-0.524379</td>\n",
       "      <td>0.224060</td>\n",
       "      <td>0.899746</td>\n",
       "      <td>-0.565012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213436</td>\n",
       "      <td>-0.942525</td>\n",
       "      <td>-0.526819</td>\n",
       "      <td>-1.156992</td>\n",
       "      <td>0.311211</td>\n",
       "      <td>-0.746647</td>\n",
       "      <td>0.040996</td>\n",
       "      <td>0.102038</td>\n",
       "      <td>-0.475031</td>\n",
       "      <td>6.966713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29474</th>\n",
       "      <td>1.399590</td>\n",
       "      <td>-0.590701</td>\n",
       "      <td>0.168619</td>\n",
       "      <td>-1.029950</td>\n",
       "      <td>-0.539806</td>\n",
       "      <td>0.040444</td>\n",
       "      <td>-0.712567</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>-0.971747</td>\n",
       "      <td>0.756801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102398</td>\n",
       "      <td>0.168269</td>\n",
       "      <td>-0.166639</td>\n",
       "      <td>-0.810250</td>\n",
       "      <td>0.505083</td>\n",
       "      <td>-0.232340</td>\n",
       "      <td>0.011409</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>-0.578115</td>\n",
       "      <td>0.125874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276481</th>\n",
       "      <td>-0.432071</td>\n",
       "      <td>1.647895</td>\n",
       "      <td>-1.669361</td>\n",
       "      <td>-0.349504</td>\n",
       "      <td>0.785785</td>\n",
       "      <td>-0.630647</td>\n",
       "      <td>0.276990</td>\n",
       "      <td>0.586025</td>\n",
       "      <td>-0.484715</td>\n",
       "      <td>-1.376648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358932</td>\n",
       "      <td>0.873663</td>\n",
       "      <td>-0.178642</td>\n",
       "      <td>-0.017171</td>\n",
       "      <td>-0.207392</td>\n",
       "      <td>-0.157756</td>\n",
       "      <td>-0.237386</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.967960</td>\n",
       "      <td>-0.286713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278846</th>\n",
       "      <td>2.014160</td>\n",
       "      <td>-0.137394</td>\n",
       "      <td>-1.015839</td>\n",
       "      <td>0.327269</td>\n",
       "      <td>-0.182179</td>\n",
       "      <td>-0.956571</td>\n",
       "      <td>0.043241</td>\n",
       "      <td>-0.160746</td>\n",
       "      <td>0.363241</td>\n",
       "      <td>0.259452</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238644</td>\n",
       "      <td>-0.616400</td>\n",
       "      <td>0.347045</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>-0.360196</td>\n",
       "      <td>0.174730</td>\n",
       "      <td>-0.078043</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>0.983816</td>\n",
       "      <td>-0.295245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75723</th>\n",
       "      <td>-1.994348</td>\n",
       "      <td>1.503076</td>\n",
       "      <td>-0.365560</td>\n",
       "      <td>0.780223</td>\n",
       "      <td>-0.957956</td>\n",
       "      <td>0.038648</td>\n",
       "      <td>-0.453702</td>\n",
       "      <td>1.553565</td>\n",
       "      <td>-0.561964</td>\n",
       "      <td>-0.100318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224820</td>\n",
       "      <td>0.319275</td>\n",
       "      <td>-0.081356</td>\n",
       "      <td>-0.366704</td>\n",
       "      <td>-0.269380</td>\n",
       "      <td>-0.278170</td>\n",
       "      <td>0.082042</td>\n",
       "      <td>-0.015071</td>\n",
       "      <td>-0.334539</td>\n",
       "      <td>0.750909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252263</th>\n",
       "      <td>-0.234567</td>\n",
       "      <td>0.733694</td>\n",
       "      <td>0.486250</td>\n",
       "      <td>-0.718186</td>\n",
       "      <td>0.782227</td>\n",
       "      <td>-0.788837</td>\n",
       "      <td>1.056307</td>\n",
       "      <td>-0.175016</td>\n",
       "      <td>-0.244864</td>\n",
       "      <td>-0.708527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202040</td>\n",
       "      <td>-0.574857</td>\n",
       "      <td>-0.024845</td>\n",
       "      <td>-0.428558</td>\n",
       "      <td>-0.563551</td>\n",
       "      <td>0.159926</td>\n",
       "      <td>0.094924</td>\n",
       "      <td>0.163736</td>\n",
       "      <td>0.834105</td>\n",
       "      <td>-0.167972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221246</th>\n",
       "      <td>0.040441</td>\n",
       "      <td>-0.109737</td>\n",
       "      <td>-1.266430</td>\n",
       "      <td>1.004783</td>\n",
       "      <td>2.223390</td>\n",
       "      <td>-0.670372</td>\n",
       "      <td>0.490662</td>\n",
       "      <td>-0.033739</td>\n",
       "      <td>-0.307052</td>\n",
       "      <td>0.402303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341151</td>\n",
       "      <td>0.930041</td>\n",
       "      <td>0.162391</td>\n",
       "      <td>-1.180279</td>\n",
       "      <td>-1.484172</td>\n",
       "      <td>-0.619133</td>\n",
       "      <td>0.357845</td>\n",
       "      <td>0.354379</td>\n",
       "      <td>0.678662</td>\n",
       "      <td>-0.200979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81910</th>\n",
       "      <td>-0.495048</td>\n",
       "      <td>0.991481</td>\n",
       "      <td>1.671584</td>\n",
       "      <td>-0.342474</td>\n",
       "      <td>0.470012</td>\n",
       "      <td>-0.348503</td>\n",
       "      <td>0.996077</td>\n",
       "      <td>-0.351891</td>\n",
       "      <td>-0.219231</td>\n",
       "      <td>0.579396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.324995</td>\n",
       "      <td>-0.474178</td>\n",
       "      <td>-0.145562</td>\n",
       "      <td>-0.011279</td>\n",
       "      <td>-0.162997</td>\n",
       "      <td>0.020511</td>\n",
       "      <td>0.040529</td>\n",
       "      <td>-0.269775</td>\n",
       "      <td>-0.300080</td>\n",
       "      <td>-0.257483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59490</th>\n",
       "      <td>-1.590486</td>\n",
       "      <td>0.992415</td>\n",
       "      <td>-0.512841</td>\n",
       "      <td>1.120752</td>\n",
       "      <td>-1.916756</td>\n",
       "      <td>3.142176</td>\n",
       "      <td>2.120463</td>\n",
       "      <td>-3.819649</td>\n",
       "      <td>0.209349</td>\n",
       "      <td>-0.028753</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.822474</td>\n",
       "      <td>0.108047</td>\n",
       "      <td>-3.362671</td>\n",
       "      <td>-1.076905</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>-0.307649</td>\n",
       "      <td>0.125750</td>\n",
       "      <td>-0.607226</td>\n",
       "      <td>-0.420969</td>\n",
       "      <td>12.367972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56962 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1        V2         V3        V4         V5        V6  \\\n",
       "43428  -16.526507  8.584972 -18.649853  9.505594 -13.793819 -2.832404   \n",
       "49906    0.339812 -2.743745  -0.134070 -1.385729  -1.451413  1.015887   \n",
       "29474    1.399590 -0.590701   0.168619 -1.029950  -0.539806  0.040444   \n",
       "276481  -0.432071  1.647895  -1.669361 -0.349504   0.785785 -0.630647   \n",
       "278846   2.014160 -0.137394  -1.015839  0.327269  -0.182179 -0.956571   \n",
       "...           ...       ...        ...       ...        ...       ...   \n",
       "75723   -1.994348  1.503076  -0.365560  0.780223  -0.957956  0.038648   \n",
       "252263  -0.234567  0.733694   0.486250 -0.718186   0.782227 -0.788837   \n",
       "221246   0.040441 -0.109737  -1.266430  1.004783   2.223390 -0.670372   \n",
       "81910   -0.495048  0.991481   1.671584 -0.342474   0.470012 -0.348503   \n",
       "59490   -1.590486  0.992415  -0.512841  1.120752  -1.916756  3.142176   \n",
       "\n",
       "               V7        V8        V9        V10  ...       V21       V22  \\\n",
       "43428  -16.701694  7.517344 -8.507059 -14.110184  ...  1.190739 -1.127670   \n",
       "49906   -0.524379  0.224060  0.899746  -0.565012  ... -0.213436 -0.942525   \n",
       "29474   -0.712567  0.002299 -0.971747   0.756801  ...  0.102398  0.168269   \n",
       "276481   0.276990  0.586025 -0.484715  -1.376648  ...  0.358932  0.873663   \n",
       "278846   0.043241 -0.160746  0.363241   0.259452  ... -0.238644 -0.616400   \n",
       "...           ...       ...       ...        ...  ...       ...       ...   \n",
       "75723   -0.453702  1.553565 -0.561964  -0.100318  ...  0.224820  0.319275   \n",
       "252263   1.056307 -0.175016 -0.244864  -0.708527  ... -0.202040 -0.574857   \n",
       "221246   0.490662 -0.033739 -0.307052   0.402303  ...  0.341151  0.930041   \n",
       "81910    0.996077 -0.351891 -0.219231   0.579396  ... -0.324995 -0.474178   \n",
       "59490    2.120463 -3.819649  0.209349  -0.028753  ... -1.822474  0.108047   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  \\\n",
       "43428  -2.358579  0.673461 -1.413700 -0.462762 -2.018575 -1.042804   \n",
       "49906  -0.526819 -1.156992  0.311211 -0.746647  0.040996  0.102038   \n",
       "29474  -0.166639 -0.810250  0.505083 -0.232340  0.011409  0.004634   \n",
       "276481 -0.178642 -0.017171 -0.207392 -0.157756 -0.237386  0.001934   \n",
       "278846  0.347045  0.061561 -0.360196  0.174730 -0.078043 -0.070571   \n",
       "...          ...       ...       ...       ...       ...       ...   \n",
       "75723  -0.081356 -0.366704 -0.269380 -0.278170  0.082042 -0.015071   \n",
       "252263 -0.024845 -0.428558 -0.563551  0.159926  0.094924  0.163736   \n",
       "221246  0.162391 -1.180279 -1.484172 -0.619133  0.357845  0.354379   \n",
       "81910  -0.145562 -0.011279 -0.162997  0.020511  0.040529 -0.269775   \n",
       "59490  -3.362671 -1.076905 -0.869555 -0.307649  0.125750 -0.607226   \n",
       "\n",
       "        scaled_time  scaled_value  \n",
       "43428     -0.507399      4.785874  \n",
       "49906     -0.475031      6.966713  \n",
       "29474     -0.578115      0.125874  \n",
       "276481     0.967960     -0.286713  \n",
       "278846     0.983816     -0.295245  \n",
       "...             ...           ...  \n",
       "75723     -0.334539      0.750909  \n",
       "252263     0.834105     -0.167972  \n",
       "221246     0.678662     -0.200979  \n",
       "81910     -0.300080     -0.257483  \n",
       "59490     -0.420969     12.367972  \n",
       "\n",
       "[56962 rows x 30 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop pre process columns\n",
    "train_scaled_value = preprocessor.fit_transform(X_train)\n",
    "X_train.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "\n",
    "test_scaled_value = preprocessor.transform(X_test)\n",
    "X_test.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "\n",
    "X_train[['scaled_time', 'scaled_value']] = train_scaled_value\n",
    "X_test[['scaled_time', 'scaled_value']] = test_scaled_value\n",
    "\n",
    "X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c2ff7d",
   "metadata": {},
   "source": [
    "#### 2.1 Splitting the Data - NearMiss (Under sampling Technique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d454372a",
   "metadata": {},
   "source": [
    "Due to the significant class imbalance in the dataset, machine learning techniques like Decision Trees and Logistic Regression tend to be **biased towards the majority class**.\n",
    "\n",
    "As a result, these models are more likely to **predict transactions as valid rather than fraudulent**, simply because valid transactions dominate the dataset.\n",
    "\n",
    "NearMiss is an under-sampling technique. It aims to balance class distribution by randomly eliminating majority class examples.\n",
    "\n",
    "Sources: https://www.researchgate.net/profile/Rahul-Pandya-7/publication/367510232_Heuristic_Approach_of_Over-Sampling_and_Under-_Sampling_in_Fraud_Detection/links/63d54b2d64fc860638f55f64/Heuristic-Approach-of-Over-Sampling-and-Under-Sampling-in-Fraud-Detection.pdf \\\n",
    "''This algorithm will in general eliminate cases of majority part classes when examples of two classes that are close.''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85dd030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to fit logistic regression with the imbalance data\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2485d231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisiticRegression\n",
      "Model performance for Training set\n",
      "- Training Accuracy Score: 0.9992\n",
      "- Training Precision Score: 0.6294\n",
      "- Training Recall Score: 0.8953\n",
      "- F1 Score: 0.7392\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Testing Accuracy Score: 0.9991\n",
      "- Testing Precision Score: 0.8636\n",
      "- Testing Recall Score: 0.5816\n",
      "- F1 Score: 0.6951\n",
      "===================================\n",
      "\n",
      "\n",
      "K-NeighborsClassifier\n",
      "Model performance for Training set\n",
      "- Training Accuracy Score: 0.9996\n",
      "- Training Precision Score: 0.7843\n",
      "- Training Recall Score: 0.9537\n",
      "- F1 Score: 0.8607\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Testing Accuracy Score: 0.9995\n",
      "- Testing Precision Score: 0.9481\n",
      "- Testing Recall Score: 0.7449\n",
      "- F1 Score: 0.8343\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"LogisiticRegression\": LogisticRegression(max_iter = 1000000),\n",
    "    \"K-NeighborsClassifier\": KNeighborsClassifier(),\n",
    "}\n",
    "\n",
    "model_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    training_accuracy = accuracy_score(y_train_pred, y_train)     \n",
    "    training_precision = precision_score(y_train_pred, y_train)     \n",
    "    training_recall = recall_score(y_train_pred, y_train)     \n",
    "    training_f1 = f1_score(y_train_pred, y_train)     \n",
    "    \n",
    "    testing_accuracy = accuracy_score(y_test, y_test_pred)     \n",
    "    testing_precision = precision_score(y_test, y_test_pred)     \n",
    "    testing_recall = recall_score(y_test, y_test_pred)     \n",
    "    testing_f1 = f1_score(y_test, y_test_pred)     \n",
    "    \n",
    "    #Get name of model to print\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Training Accuracy Score: {:.4f}\".format(training_accuracy))\n",
    "    print(\"- Training Precision Score: {:.4f}\".format(training_precision))\n",
    "    print(\"- Training Recall Score: {:.4f}\".format(training_recall))\n",
    "    print(\"- F1 Score: {:.4f}\".format(training_f1))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Testing Accuracy Score: {:.4f}\".format(testing_accuracy))\n",
    "    print(\"- Testing Precision Score: {:.4f}\".format(testing_precision))\n",
    "    print(\"- Testing Recall Score: {:.4f}\".format(testing_recall))\n",
    "    print(\"- F1 Score: {:.4f}\".format(testing_f1))\n",
    "\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e8f98",
   "metadata": {},
   "source": [
    "#####  Insights\n",
    "- Even though Training and Testing accuracy score is very high, Testing recall score is very low (0.5816 and 0.7449) for both models\n",
    "- This suggest that models **fail to recognize** fraud transactions from non-fraud transaction\n",
    "- This is due to high class imbalance, where the **model bias the domniant class** (which is non fraud in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c68f99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LogisticRegression ===\n",
      "Mean Training Accuracy:   0.963 (+/- 0.004)\n",
      "Mean Training Precision:  0.042 (+/- 0.006)\n",
      "Mean Training Recall:     0.911 (+/- 0.024)\n",
      "Mean Training F1 Score:   0.080 (+/- 0.010)\n",
      "\n",
      "--- Testing Results ---\n",
      "Testing Accuracy:  0.9632\n",
      "Testing Precision: 0.0417\n",
      "Testing Recall:    0.9286\n",
      "Testing F1:        0.0799\n",
      "==========================================================================================\n",
      "=== KNeighborsClassifier ===\n",
      "Mean Training Accuracy:   0.973 (+/- 0.005)\n",
      "Mean Training Precision:  0.055 (+/- 0.008)\n",
      "Mean Training Recall:     0.888 (+/- 0.027)\n",
      "Mean Training F1 Score:   0.104 (+/- 0.015)\n",
      "\n",
      "--- Testing Results ---\n",
      "Testing Accuracy:  0.9668\n",
      "Testing Precision: 0.0452\n",
      "Testing Recall:    0.9082\n",
      "Testing F1:        0.0860\n",
      "==========================================================================================\n",
      "=== Support Vector Classifier ===\n",
      "Mean Training Accuracy:   0.984 (+/- 0.003)\n",
      "Mean Training Precision:  0.090 (+/- 0.016)\n",
      "Mean Training Recall:     0.883 (+/- 0.039)\n",
      "Mean Training F1 Score:   0.163 (+/- 0.026)\n",
      "\n",
      "--- Testing Results ---\n",
      "Testing Accuracy:  0.9787\n",
      "Testing Precision: 0.0681\n",
      "Testing Recall:    0.8980\n",
      "Testing F1:        0.1266\n",
      "==========================================================================================\n",
      "=== DecisionTreeClassifier ===\n",
      "Mean Training Accuracy:   0.899 (+/- 0.008)\n",
      "Mean Training Precision:  0.016 (+/- 0.001)\n",
      "Mean Training Recall:     0.916 (+/- 0.043)\n",
      "Mean Training F1 Score:   0.031 (+/- 0.003)\n",
      "\n",
      "--- Testing Results ---\n",
      "Testing Accuracy:  0.9001\n",
      "Testing Precision: 0.0154\n",
      "Testing Recall:    0.9082\n",
      "Testing F1:        0.0303\n",
      "==========================================================================================\n",
      "=== XGBClassifier ===\n",
      "Mean Training Accuracy:   0.959 (+/- 0.006)\n",
      "Mean Training Precision:  0.038 (+/- 0.005)\n",
      "Mean Training Recall:     0.919 (+/- 0.038)\n",
      "Mean Training F1 Score:   0.073 (+/- 0.008)\n",
      "\n",
      "--- Testing Results ---\n",
      "Testing Accuracy:  0.9613\n",
      "Testing Precision: 0.0402\n",
      "Testing Recall:    0.9388\n",
      "Testing F1:        0.0770\n",
      "==========================================================================================\n",
      "=== CatBoosting Classifier ===\n",
      "Mean Training Accuracy:   0.974 (+/- 0.006)\n",
      "Mean Training Precision:  0.061 (+/- 0.015)\n",
      "Mean Training Recall:     0.901 (+/- 0.031)\n",
      "Mean Training F1 Score:   0.114 (+/- 0.025)\n",
      "\n",
      "--- Testing Results ---\n",
      "Testing Accuracy:  0.9783\n",
      "Testing Precision: 0.0697\n",
      "Testing Recall:    0.9388\n",
      "Testing F1:        0.1298\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, \n",
    "                             recall_score, f1_score, classification_report)\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "\n",
    "# Imbalanced-learn imports\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "\n",
    "\n",
    "# 1. Define the undersampling strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# 2. Define the models you want to evaluate\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1_000_000),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(), \n",
    "    \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "    # Add more models if needed\n",
    "}\n",
    "\n",
    "# 3. Define the scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "# 4. Set up stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 5. Iterate over each model, build the pipeline, and evaluate\n",
    "for model_name, model in models.items():\n",
    "    # Create a pipeline for undersampling + model\n",
    "    pipeline = imbpipeline(steps=[\n",
    "        ('undersample', undersample),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Perform cross-validation to get training metrics\n",
    "    cv_results = cross_validate(\n",
    "        pipeline,\n",
    "        X_train, \n",
    "        y_train, \n",
    "        cv=skf, \n",
    "        scoring=scoring, \n",
    "        return_train_score=False\n",
    "    )\n",
    "\n",
    "    # Fit the pipeline on the entire training set\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    print(f\"=== {model_name} ===\")\n",
    "    # Training metrics (mean of cross-validation folds)\n",
    "    print(\"Mean Training Accuracy:   {:.3f} (+/- {:.3f})\"\n",
    "          .format(cv_results['test_accuracy'].mean(),\n",
    "                  cv_results['test_accuracy'].std()))\n",
    "    print(\"Mean Training Precision:  {:.3f} (+/- {:.3f})\"\n",
    "          .format(cv_results['test_precision'].mean(),\n",
    "                  cv_results['test_precision'].std()))\n",
    "    print(\"Mean Training Recall:     {:.3f} (+/- {:.3f})\"\n",
    "          .format(cv_results['test_recall'].mean(),\n",
    "                  cv_results['test_recall'].std()))\n",
    "    print(\"Mean Training F1 Score:   {:.3f} (+/- {:.3f})\"\n",
    "          .format(cv_results['test_f1'].mean(),\n",
    "                  cv_results['test_f1'].std()))\n",
    "\n",
    "    # Testing metrics (evaluating on the holdout set X_test, y_test)\n",
    "    testing_accuracy = accuracy_score(y_test, y_pred)\n",
    "    testing_precision = precision_score(y_test, y_pred)\n",
    "    testing_recall = recall_score(y_test, y_pred)\n",
    "    testing_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n--- Testing Results ---\")\n",
    "    print(\"Testing Accuracy:  {:.4f}\".format(testing_accuracy))\n",
    "    print(\"Testing Precision: {:.4f}\".format(testing_precision))\n",
    "    print(\"Testing Recall:    {:.4f}\".format(testing_recall))\n",
    "    print(\"Testing F1:        {:.4f}\".format(testing_f1))\n",
    "\n",
    "    print(\"===\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6719bec",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- Huge improvement for recall 0.9286 for Logistic Regression (from 0.58)\n",
    "- High accuracy and recall score for testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72459f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
