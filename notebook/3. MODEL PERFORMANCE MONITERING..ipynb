{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GOAL: Monitering Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define Random State\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing all the data before spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/fraud.csv')\n",
    "df.drop(['prev_address_months_count', 'intended_balcon_amount', 'device_fraud_count'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['month'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting the data by month\n",
    "\n",
    "source: https://arxiv.org/pdf/2401.05240v2\n",
    "\n",
    "According to the paper's methodology, we split by month:\n",
    "  - Training: months 1, 2, 3, 4, 5\n",
    "  - Validation: month 6\n",
    "  - Test: months 7, 8\n",
    " - [Ref: Jesus et al., 2022 - \"training set: month 1-5, validation set: month 6, testing set: months 7-8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set months: [1 2 3 4 5]\n",
      "Val   set months: [6]\n",
      "Test  set months: [7]\n",
      "Shapes:\n",
      " X_train: (662549, 28)  y_train: (662549,)\n",
      " X_val:   (108168, 28)  y_val:   (108168,)\n",
      " X_test:  (96843, 28)  y_test:  (96843,)\n"
     ]
    }
   ],
   "source": [
    "# Split your dataset BEFORE fitting any preprocessing to avoid data leakage\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_months = [1, 2, 3, 4, 5]\n",
    "val_month = [6]\n",
    "test_months = [7, 8]\n",
    "\n",
    "df_train = df[df[\"month\"].isin(train_months)]\n",
    "df_val = df[df['month'].isin(val_month)]\n",
    "df_test = df[df['month'].isin(test_months)]\n",
    "\n",
    "# Print quick info for sanity check\n",
    "print(\"Train set months:\", df_train['month'].unique())\n",
    "print(\"Val   set months:\", df_val['month'].unique())\n",
    "print(\"Test  set months:\", df_test['month'].unique())\n",
    "\n",
    "# Define target variable\n",
    "target_variable = 'fraud_bool'\n",
    "\n",
    "X_train = df_train.drop(columns=target_variable, axis=1)\n",
    "X_val = df_val.drop(columns=target_variable, axis=1)\n",
    "X_test = df_test.drop(columns=target_variable, axis=1)\n",
    "\n",
    "y_train = df_train[target_variable]\n",
    "y_val = df_val[target_variable]\n",
    "y_test = df_test[target_variable]\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\" X_train:\", X_train.shape, \" y_train:\", y_train.shape)\n",
    "print(\" X_val:  \", X_val.shape,   \" y_val:  \", y_val.shape)\n",
    "print(\" X_test: \", X_test.shape,  \" y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature types\n",
    "\n",
    "num_features = ['income', 'name_email_similarity', 'current_address_months_count', 'customer_age', 'days_since_request'\n",
    "                    , 'zip_count_4w', 'velocity_6h', 'velocity_24h', 'velocity_4w', 'bank_branch_count_8w', \n",
    "                    'date_of_birth_distinct_emails_4w', 'credit_risk_score', 'bank_months_count', 'proposed_credit_limit',  'session_length_in_minutes',\n",
    "                    'device_distinct_emails_8w', 'month']\n",
    "\n",
    "\n",
    "cat_features = ['payment_type', 'employment_status', 'housing_status',\n",
    "                         'source', 'device_os']\n",
    "\n",
    "binary_features = [\n",
    "    'email_is_free',\n",
    "    'phone_home_valid',\n",
    "    'phone_mobile_valid',\n",
    "    'has_other_cards',\n",
    "    'foreign_request',\n",
    "    'keep_alive_session',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# ------------------------------------------Numerical----------------------------------------\n",
    "# a. Impute Numerical Features\n",
    "# Median imputation is preferred when the distribution is skewed\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# Fit the imputer on the training data\n",
    "num_imputer.fit(X_train[num_features])\n",
    "\n",
    "# Transform on training, validation data and test data\n",
    "\n",
    "# Transform numeric features on X_train \n",
    "X_train_numeric = pd.DataFrame(\n",
    "    num_imputer.transform(X_train[num_features]),\n",
    "    columns=num_features,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# Transform numeric features on X_val \n",
    "X_val_numeric = pd.DataFrame(\n",
    "    num_imputer.transform(X_val[num_features]),\n",
    "    columns=num_features,\n",
    "    index=X_val.index\n",
    ")\n",
    "\n",
    "# Transform numeric features on X_test \n",
    "X_test_numeric = pd.DataFrame(\n",
    "    num_imputer.transform(X_test[num_features]),\n",
    "    columns=num_features,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# ------------------------------------------Categorical----------------------------------------\n",
    "# b. Impute Categorical Features\n",
    "# Initialize the imputer for categorical features\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Fit the imputer on the training data\n",
    "categorical_imputer.fit(X_train[cat_features])\n",
    "\n",
    "# # Transform on training, validation data and test data\n",
    "# Transform categorical features on X_train \n",
    "X_train_categorical = pd.DataFrame(\n",
    "    categorical_imputer.transform(X_train[cat_features]),\n",
    "    columns=cat_features,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# Transform categorical features on X_val\n",
    "X_val_categorical = pd.DataFrame(\n",
    "    categorical_imputer.transform(X_val[cat_features]),\n",
    "    columns=cat_features,\n",
    "    index=X_val.index\n",
    ")\n",
    "\n",
    "# Transform categorical features on X_test\n",
    "X_test_categorical = pd.DataFrame(\n",
    "    categorical_imputer.transform(X_test[cat_features]),\n",
    "    columns=cat_features,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# ------------------------------------------Binary----------------------------------------\n",
    "# c. Impute Binary Features\n",
    "\n",
    "# Initialize the imputer for binary features\n",
    "binary_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Fit the imputer on the training data\n",
    "binary_imputer.fit(X_train[binary_features])\n",
    "\n",
    "# Transform on train, validation and test data\n",
    "# Transform binary features on X_train\n",
    "X_train_bin = pd.DataFrame(\n",
    "    binary_imputer.transform(X_train[binary_features]),\n",
    "    columns=binary_features,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# Transform binary features on X_val\n",
    "X_val_bin = pd.DataFrame(\n",
    "    binary_imputer.transform(X_val[binary_features]),\n",
    "    columns=binary_features,\n",
    "    index=X_val.index\n",
    ")\n",
    "\n",
    "# Transform binary features on X_test\n",
    "X_test_bin = pd.DataFrame(\n",
    "    binary_imputer.transform(X_test[binary_features]),\n",
    "    columns=binary_features,\n",
    "    index=X_test.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine numerical and categorical features and binary features\n",
    "X_train_imputed = pd.concat([X_train_numeric, X_train_categorical, X_train_bin], axis=1)\n",
    "X_val_imputed = pd.concat([X_val_numeric, X_val_categorical, X_val_bin], axis=1)\n",
    "X_test_imputed = pd.concat([X_test_numeric, X_test_categorical, X_test_bin], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling and Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Every step is base on notebook 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\project\\Credit_Fraud_endToEnd\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "# ------------------------------------------Numerical----------------------------------------\n",
    "# a. Scale Numerical Features\n",
    "# Initialize the scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "scaler.fit(X_train_imputed[num_features])\n",
    "\n",
    "# Transform on training, validating and testing data\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_train_imputed[num_features]),\n",
    "    columns=num_features,\n",
    "    index=X_train_imputed.index\n",
    ")\n",
    "\n",
    "X_val_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_val_imputed[num_features]),\n",
    "    columns=num_features,\n",
    "    index=X_val_imputed.index\n",
    ")\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test_imputed[num_features]),\n",
    "    columns=num_features,\n",
    "    index=X_test_imputed.index\n",
    ")\n",
    "\n",
    "# ------------------------------------------Categorical----------------------------------------\n",
    "# b. Encode Categorical Features\n",
    "# Initialize the encoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit the encoder on the training data\n",
    "encoder.fit(X_train_imputed[cat_features])\n",
    "\n",
    "# Transform on training, validating and testing data\n",
    "X_train_encoded = pd.DataFrame(\n",
    "    encoder.transform(X_train_imputed[cat_features]),\n",
    "    columns=encoder.get_feature_names_out(cat_features),\n",
    "    index=X_train_imputed.index\n",
    ")\n",
    "\n",
    "X_val_encoded = pd.DataFrame(\n",
    "    encoder.transform(X_val_imputed[cat_features]),\n",
    "    columns=encoder.get_feature_names_out(cat_features),\n",
    "    index=X_val_imputed.index\n",
    ")\n",
    "\n",
    "X_test_encoded = pd.DataFrame(\n",
    "    encoder.transform(X_test_imputed[cat_features]),\n",
    "    columns=encoder.get_feature_names_out(cat_features),\n",
    "    index=X_test_imputed.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed validation Data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(108168, 49)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine scaled numerical and encoded categorical features\n",
    "X_train_preprocessed = pd.concat([X_train_scaled, X_train_encoded, X_train_bin], axis=1)\n",
    "X_val_preprocessed = pd.concat([X_val_scaled, X_val_encoded, X_val_bin], axis=1)\n",
    "X_test_preprocessed = pd.concat([X_test_scaled, X_test_encoded, X_test_bin], axis=1)\n",
    "\n",
    "print(\"Preprocessed validation Data:\")\n",
    "X_val_preprocessed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selection with mutual information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chose top 30 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28452\\1275658607.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Prepare numerical features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmutual_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmutual_info_classif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_preprocessed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmutual_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project\\Credit_Fraud_endToEnd\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m                     )\n\u001b[0;32m    213\u001b[0m                 ):\n\u001b[1;32m--> 214\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m                 \u001b[1;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project\\Credit_Fraud_endToEnd\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_classif\u001b[1;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \"\"\"\n\u001b[0;32m    489\u001b[0m     \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_estimate_mi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscrete_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\project\\Credit_Fraud_endToEnd\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[1;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    302\u001b[0m         )\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m     mi = [\n\u001b[0m\u001b[0;32m    305\u001b[0m         \u001b[0m_compute_mi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscrete_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscrete_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscrete_feature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_iterate_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscrete_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project\\Credit_Fraud_endToEnd\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     mi = [\n\u001b[1;32m--> 305\u001b[1;33m         \u001b[0m_compute_mi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscrete_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscrete_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscrete_feature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_iterate_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscrete_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     ]\n",
      "\u001b[1;32md:\\project\\Credit_Fraud_endToEnd\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi\u001b[1;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mx_discrete\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my_discrete\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_compute_mi_cc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project\\Credit_Fraud_endToEnd\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi_cd\u001b[1;34m(c, d, n_neighbors)\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m             \u001b[0mradius\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnextafter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mk_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project\\Credit_Fraud_endToEnd\\venv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    875\u001b[0m                     \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m                 )\n\u001b[1;32m--> 877\u001b[1;33m             chunked_results = Parallel(n_jobs, prefer=\"threads\")(\n\u001b[0m\u001b[0;32m    878\u001b[0m                 delayed(_tree_query_parallel_helper)(\n\u001b[0;32m    879\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project\\Credit_Fraud_endToEnd\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         )\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project\\Credit_Fraud_endToEnd\\venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m         \u001b[1;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project\\Credit_Fraud_endToEnd\\venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1847\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project\\Credit_Fraud_endToEnd\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\project\\Credit_Fraud_endToEnd\\venv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \"\"\"\n\u001b[1;32m--> 683\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# a. Mutual information \n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "#Prepare numerical features\n",
    "\n",
    "mutual_info = mutual_info_classif(X_train_preprocessed, y_train)\n",
    "mutual_info\n",
    "\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = X_train_preprocessed.columns\n",
    "mutual_info.sort_values(ascending=False)\n",
    "\n",
    "# Choosing top 30 features\n",
    "feature_to_drop = mutual_info.sort_values(ascending=False)[31:].index.tolist()\n",
    "\n",
    "X_train_preprocessed.drop(columns=feature_to_drop, axis=1, inplace=True)\n",
    "X_val_preprocessed.drop(columns=feature_to_drop, axis=1, inplace=True)\n",
    "X_test_preprocessed.drop(columns=feature_to_drop, axis=1, inplace=True)\n",
    "X_train_preprocessed.shape,X_val_preprocessed, X_test_preprocessed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training, assesing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Model\n",
    "from lightgbm import LGBMClassifier as lgb\n",
    "\n",
    "# Scoring metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# import for oversampling\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "\n",
    "def find_best_threshold_for_max_recall_at_fpr(\n",
    "    val_probs, y_val, \n",
    "    target_fpr=0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    Given validation set probabilities (val_probs) and ground truth (y_val),\n",
    "    find the threshold that yields the highest recall subject to FPR <= target_fpr.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    val_probs : np.ndarray\n",
    "        Predicted probabilities for the positive class on the validation set.\n",
    "    y_val : np.ndarray\n",
    "        True labels (0 or 1) for the validation set.\n",
    "    target_fpr : float\n",
    "        The maximum allowed false positive rate.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    best_threshold : float\n",
    "        The threshold that yields the maximum recall while keeping FPR <= target_fpr.\n",
    "    best_fpr : float\n",
    "        The FPR at that threshold.\n",
    "    best_recall : float\n",
    "        The recall at that threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort the probabilities in ascending order\n",
    "    sorted_thresholds = np.sort(val_probs)\n",
    "    \n",
    "    best_threshold = 0.0\n",
    "    best_fpr = 1.0\n",
    "    best_recall = 0.0\n",
    "    \n",
    "    # We'll try each threshold in ascending order.\n",
    "    # For each threshold, we measure FPR and recall.\n",
    "    for t in sorted_thresholds:\n",
    "        preds = (val_probs >= t).astype(int)\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, preds, labels=[0,1]).ravel()\n",
    "        \n",
    "        # Compute FPR = FP / (FP + TN)\n",
    "        # Avoid division by zero if TN+FP=0\n",
    "        denom = (fp + tn) if (fp+tn) else 1e-15\n",
    "        current_fpr = fp / denom\n",
    "        \n",
    "        # Compute recall = TP / (TP + FN)\n",
    "        # Avoid division by zero if TP+FN=0\n",
    "        denom_pos = (tp + fn) if (tp+fn) else 1e-15\n",
    "        current_recall = tp / denom_pos\n",
    "        \n",
    "        # We only consider thresholds where FPR <= target_fpr\n",
    "        if current_fpr <= target_fpr:\n",
    "            # Among those, pick the one that yields the highest recall\n",
    "            if current_recall > best_recall:\n",
    "                best_threshold = t\n",
    "                best_fpr = current_fpr\n",
    "                best_recall = current_recall\n",
    "    \n",
    "    return best_threshold, best_fpr, best_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lightgbm import LGBMClassifier as lgb\n",
    "\n",
    "def run_experiment(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    X_test, y_test,\n",
    "    n_bootstraps=5,\n",
    "    oversampling=False,\n",
    "    random_seed=42,\n",
    "    target_fpr=0.2  # Desired FPR for validation\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs a training+evaluation experiment across multiple bootstraps, fixing\n",
    "    a threshold that yields <= target FPR on the validation set, and then\n",
    "    measuring precision, recall, and FPR on the test set at that threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, y_train : Training features and labels (DataFrame or Series)\n",
    "    X_val,   y_val   : Validation features and labels\n",
    "    X_test,  y_test  : Test features and labels\n",
    "    n_bootstraps     : Number of bootstrap iterations\n",
    "    oversampling     : Whether to apply SMOTE oversampling in each bootstrap\n",
    "    random_seed      : Random seed for reproducibility\n",
    "    target_fpr       : Desired FPR (false positive rate) on the validation set\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    precision_list, recall_list, fpr_list : Lists of precision, recall, and FPR across bootstraps\n",
    "    \"\"\"\n",
    "    \n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    fpr_list = []\n",
    "    decision_threshold = None  # We'll set this only in the first bootstrap\n",
    "    \n",
    "    np.random.seed(random_seed)  # Reproducibility\n",
    "    \n",
    "    for i in range(n_bootstraps):\n",
    "        print(f\"\\n=== Bootstrap Iteration #{i} (Oversampling={oversampling}) ===\")\n",
    "        \n",
    "        # ---------------------------\n",
    "        # 1) Bootstrapping\n",
    "        # ---------------------------\n",
    "        indices = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        X_train_boot = X_train.iloc[indices]\n",
    "        y_train_boot = y_train.iloc[indices]\n",
    "        \n",
    "        # ---------------------------\n",
    "        # 2) (Optional) Oversampling\n",
    "        # ---------------------------\n",
    "        if oversampling:\n",
    "            smote_obj = SMOTE(random_state=i)  # different random state each iteration\n",
    "            X_train_boot, y_train_boot = smote_obj.fit_resample(X_train_boot, y_train_boot)\n",
    "        \n",
    "        # ---------------------------\n",
    "        # 3) Model Training\n",
    "        # ---------------------------\n",
    "        base_lgb = lgb(random_state=i)\n",
    "        base_lgb.fit(X_train_boot, y_train_boot)\n",
    "        \n",
    "        # ---------------------------\n",
    "        # 4) Threshold Setting on Validation (Only in the first iteration)\n",
    "        #    We want <= target_fpr on the validation set.\n",
    "        # ---------------------------\n",
    "        if i == 0:\n",
    "            val_probs = base_lgb.predict_proba(X_val)[:, 1]\n",
    "            \n",
    "            # Desired FPR = 5% (0.05)\n",
    "            threshold, fpr, recall_ = find_best_threshold_for_max_recall_at_fpr(\n",
    "                val_probs, \n",
    "                y_val, \n",
    "                target_fpr=target_fpr\n",
    "            )\n",
    "            \n",
    "            decision_threshold = threshold\n",
    "            print(f\"Chosen decision threshold (FPR <= {target_fpr}) = {decision_threshold:.3f}\")\n",
    "            print(f\"Resulting FPR on validation set: {fpr:.3f}\")\n",
    "            print(f\"Resulting Recall on validation set: {recall_:.3f}\")\n",
    "            \n",
    "        \n",
    "        # ---------------------------\n",
    "        # 5) Evaluate on Test\n",
    "        # ---------------------------\n",
    "        test_probs = base_lgb.predict_proba(X_test)[:, 1]\n",
    "        test_preds = (test_probs > decision_threshold).astype(int)\n",
    "        \n",
    "        # Precision / Recall\n",
    "        prec = precision_score(y_test, test_preds)\n",
    "        rec = recall_score(y_test, test_preds)\n",
    "        \n",
    "        # FPR on Test\n",
    "        tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, test_preds, labels=[0,1]).ravel()\n",
    "        denom_test = (tn_test + fp_test) if (tn_test + fp_test) else 1e-10\n",
    "        test_fpr = fp_test / denom_test\n",
    "        \n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        fpr_list.append(test_fpr)\n",
    "        \n",
    "        print(f\"Test Precision @ threshold={decision_threshold:.3f}: {prec:.3f}\")\n",
    "        print(f\"Test Recall    @ threshold={decision_threshold:.3f}: {rec:.3f}\")\n",
    "        print(f\"Test FPR       @ threshold={decision_threshold:.3f}: {test_fpr:.3f}\")\n",
    "    \n",
    "    return precision_list, recall_list, fpr_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPERIMENT 1: No Oversampling ===\n",
      "\n",
      "=== Bootstrap Iteration #0 (Oversampling=False) ===\n",
      "Chosen decision threshold (FPR <= 0.2) = 0.009\n",
      "Resulting FPR on validation set: 0.200\n",
      "Resulting Recall on validation set: 0.803\n",
      "Test Precision @ threshold=0.009: 0.059\n",
      "Test Recall    @ threshold=0.009: 0.796\n",
      "Test FPR       @ threshold=0.009: 0.190\n",
      "\n",
      "=== Bootstrap Iteration #1 (Oversampling=False) ===\n",
      "Test Precision @ threshold=0.009: 0.060\n",
      "Test Recall    @ threshold=0.009: 0.775\n",
      "Test FPR       @ threshold=0.009: 0.183\n",
      "\n",
      "=== Bootstrap Iteration #2 (Oversampling=False) ===\n",
      "Test Precision @ threshold=0.009: 0.063\n",
      "Test Recall    @ threshold=0.009: 0.769\n",
      "Test FPR       @ threshold=0.009: 0.172\n",
      "\n",
      "=== Bootstrap Iteration #3 (Oversampling=False) ===\n",
      "Test Precision @ threshold=0.009: 0.062\n",
      "Test Recall    @ threshold=0.009: 0.781\n",
      "Test FPR       @ threshold=0.009: 0.177\n",
      "\n",
      "=== Bootstrap Iteration #4 (Oversampling=False) ===\n",
      "Test Precision @ threshold=0.009: 0.061\n",
      "Test Recall    @ threshold=0.009: 0.779\n",
      "Test FPR       @ threshold=0.009: 0.179\n",
      "\n",
      "=== EXPERIMENT 2: With Oversampling ===\n",
      "\n",
      "=== Bootstrap Iteration #0 (Oversampling=True) ===\n",
      "Chosen decision threshold (FPR <= 0.2) = 0.183\n",
      "Resulting FPR on validation set: 0.200\n",
      "Resulting Recall on validation set: 0.809\n",
      "Test Precision @ threshold=0.183: 0.066\n",
      "Test Recall    @ threshold=0.183: 0.767\n",
      "Test FPR       @ threshold=0.183: 0.162\n",
      "\n",
      "=== Bootstrap Iteration #1 (Oversampling=True) ===\n",
      "Test Precision @ threshold=0.183: 0.069\n",
      "Test Recall    @ threshold=0.183: 0.774\n",
      "Test FPR       @ threshold=0.183: 0.157\n",
      "\n",
      "=== Bootstrap Iteration #2 (Oversampling=True) ===\n",
      "Test Precision @ threshold=0.183: 0.062\n",
      "Test Recall    @ threshold=0.183: 0.784\n",
      "Test FPR       @ threshold=0.183: 0.176\n",
      "\n",
      "=== Bootstrap Iteration #3 (Oversampling=True) ===\n",
      "Test Precision @ threshold=0.183: 0.069\n",
      "Test Recall    @ threshold=0.183: 0.748\n",
      "Test FPR       @ threshold=0.183: 0.151\n",
      "\n",
      "=== Bootstrap Iteration #4 (Oversampling=True) ===\n",
      "Test Precision @ threshold=0.183: 0.062\n",
      "Test Recall    @ threshold=0.183: 0.791\n",
      "Test FPR       @ threshold=0.183: 0.180\n"
     ]
    }
   ],
   "source": [
    "# C) Run Experiments (Oversample vs. No Oversample)\n",
    "# ---------------------------------\n",
    "print(\"=== EXPERIMENT 1: No Oversampling ===\")\n",
    "precision_no_os, recall_no_os, fpr_no_os = run_experiment(\n",
    "    X_train_preprocessed, y_train, X_val_preprocessed, y_val, X_test_preprocessed, y_test,\n",
    "    n_bootstraps=5,\n",
    "    oversampling=False,\n",
    "    random_seed=42,\n",
    "    target_fpr = 0.2\n",
    ")\n",
    "\n",
    "print(\"\\n=== EXPERIMENT 2: With Oversampling ===\")\n",
    "precision_os, recall_os, fpr_os = run_experiment(\n",
    "    X_train_preprocessed, y_train, X_val_preprocessed, y_val, X_test_preprocessed, y_test,\n",
    "    n_bootstraps=5,\n",
    "    oversampling=True,\n",
    "    random_seed=42,\n",
    "    target_fpr= 0.2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARISON OF RESULTS ===\n",
      "\n",
      "No Oversampling => Precision: 0.061 ± 0.001, Recall: 0.780 ± 0.009 FPR: 0.180 ± 0.006\n",
      "Oversampling   => Precision: 0.066 ± 0.003, Recall: 0.773 ± 0.015 FPR: 0.165 ± 0.011\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# D) Compare Results\n",
    "# ---------------------------\n",
    "print(\"\\n=== COMPARISON OF RESULTS ===\")\n",
    "\n",
    "mean_prec_no_os = np.mean(precision_no_os)\n",
    "std_prec_no_os = np.std(precision_no_os)\n",
    "mean_rec_no_os = np.mean(recall_no_os)\n",
    "std_rec_no_os = np.std(recall_no_os)\n",
    "mean_fpr_no_os = np.mean(fpr_no_os)\n",
    "std_fpr_no_os = np.std(fpr_no_os)\n",
    "\n",
    "mean_prec_os = np.mean(precision_os)\n",
    "std_prec_os = np.std(precision_os)\n",
    "mean_rec_os = np.mean(recall_os)\n",
    "std_rec_os = np.std(recall_os)\n",
    "mean_fpr_os = np.mean(fpr_os)\n",
    "std_fpr_os = np.std(fpr_os)\n",
    "\n",
    "print(f\"\\nNo Oversampling => Precision: {mean_prec_no_os:.3f} ± {std_prec_no_os:.3f}, \"\n",
    "        f\"Recall: {mean_rec_no_os:.3f} ± {std_rec_no_os:.3f}\",\n",
    "        f\"FPR: {mean_fpr_no_os:.3f} ± {std_fpr_no_os:.3f}\"\n",
    "        )\n",
    "print(f\"Oversampling   => Precision: {mean_prec_os:.3f} ± {std_prec_os:.3f}, \"\n",
    "        f\"Recall: {mean_rec_os:.3f} ± {std_rec_os:.3f}\", \n",
    "        f\"FPR: {mean_fpr_os:.3f} ± {std_fpr_os:.3f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
